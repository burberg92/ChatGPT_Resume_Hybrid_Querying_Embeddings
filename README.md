# Resume_LLM

This Jupyter notebook accompanies the paper "Resume Parsing Model" and provides a comprehensive walkthrough of the methodology used in the study. The paper focuses on leveraging semantic vectorization techniques and text chunking to enhance the understanding capabilities of Large Language Models (LLMs).  

Contents

## Document Chunking:
- Explanation of the need for text chunking in LLMs.
- Implementation of the RecursiveCharacterTextSplitter for efficient chunking.
- Demonstrations of how the document chunking process is applied to sample documents.

## Semantic Vectorization:
- Introduction to semantic vectorization and its importance in LLMs.
- Implementation of contextualized word embeddings using pre-trained models.
- Examples of generating semantic vectors for chunks of text.

## Chroma Vector Database:
- Implementation of database interaction using Python libraries.
- Illustrations of how vectorized data is stored, managed, and retrieved.

## Hybrid Querying:

- Introduction to the concept of hybrid querying for enhanced LLM interactions.
- Implementation of techniques for combining vectorized content with user queries.
- Examples of how hybrid querying improves the relevance and coherence of LLM responses.

License
This project is licensed under the MIT License. Feel free to use and modify the code as needed.

